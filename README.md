# AI Photo Search

A **private, AI-powered photo search system** for personal photo collections. The project enables natural-language and image-based search using CLIP embeddings, metadata filtering, and an LLM reasoning layer â€” all running securely inside AWS.

The system is designed to be **non-public by default**, accessible only from trusted devices via secure tunneling (SSM) or a private network (Tailscale).

---

## Key Features

* ğŸ” Semantic photo search using **CLIP embeddings** (image â†” text)
* ğŸ§  LLM-assisted query understanding (OpenAI GPT-4 mini)
* ğŸ–¼ï¸ Search by **text or image** with optional metadata filters
* â˜ï¸ Scalable ingestion via **S3 â†’ Lambda â†’ SQS**
* ğŸ“¦ Persistent vector storage using **Chroma + EBS**
* ğŸ” Private access via **AWS SSM** or **Tailscale**
* ğŸ³ Fully containerized with Docker

---

## High-Level Architecture

```
Phone / Browser
      â”‚
      â”‚  (SSM tunnel or Tailscale)
      â–¼
FastAPI (Docker, EC2)
      â”‚
      â”œâ”€â”€ LLM Agent (query reasoning)
      â”œâ”€â”€ CLIP Text Embeddings
      â”œâ”€â”€ CLIP Image Embeddings
      â–¼
Chroma Vector DB (EBS)
```

---

## Photo Ingestion Pipeline

### 1. Upload

Photos are uploaded (currently **manually**) to an **S3 uploads folder**.

> In the future, this can be automated (e.g. mobile photo gallery sync).

---

### 2. Lambda Processing

An S3 event triggers a Lambda function that:

* Extracts EXIF and basic metadata
* Generates thumbnails
* Stores processed images back to S3
* Sends metadata + S3 keys to **SQS**

---

### 3. Embedding Worker (EC2)

A long-running worker on EC2 consumes SQS messages:

* Downloads images from S3
* Generates **CLIP image embeddings**
* Stores embeddings + metadata in **Chroma**
* Persists everything on **EBS** (not ephemeral)

This decoupling allows ingestion to scale independently from search.

---

## Search & API Layer

A **FastAPI** application runs inside Docker on EC2 and serves both:

* Backend API
* Frontend UI

### Main Endpoints

* `/` â€“ Frontend UI
* `/search/text` â€“ Semantic text search
* `/search/image` â€“ Image similarity search
* `/health` â€“ Health check

The frontend and backend are intentionally served from the **same FastAPI server** to avoid CORS, localhost, and multi-server complexity.

---

## LLM Reasoning Layer

The system uses **OpenAI GPT-4 mini** as a *reasoning and orchestration layer*, not as a source of truth.

The LLM:

* Translates and normalizes user queries
* Decides when to:

  * perform vector similarity search
  * apply metadata filters
  * or combine both
* Calls internal tools with **strict safety rules**:

### LLM Constraints

* âŒ Never hallucinate photos
* âŒ Never invent metadata
* âŒ Never describe images not returned by tools
* âœ… Only summarize and explain tool results

This keeps the system deterministic and trustworthy.

---

## Security & Access Model

This project is **private by design**.

* âŒ No public HTTP endpoints
* âŒ No exposed authentication UI
* âŒ No public IP required

### Access Options

#### Option 1: AWS SSM (Desktop)

* Secure port forwarding using AWS credentials
* No SSH keys exposed
* Ideal for development and debugging

#### Option 2 (Recommended): Tailscale

* Creates a private WireGuard-based network
* Works across:

  * laptop
  * mobile phone
  * EC2
* Access the app via:

```
http://<tailscale-ip>:8000
```

This is the **cleanest solution** for private, multi-device access.

---

## Project Structure

```
/home/ec2-user/app
â”œâ”€â”€ agents/                 # LLM agent orchestration
â”‚   â””â”€â”€ agent_runtime.py
â”œâ”€â”€ embeddings/             # CLIP models & embedding logic
â”‚   â”œâ”€â”€ clip_model.py
â”‚   â”œâ”€â”€ image_embedder.py
â”‚   â””â”€â”€ text_embedder.py
â”œâ”€â”€ worker/                 # SQS-driven embedding worker
â”‚   â””â”€â”€ embed_images_worker.py
â”œâ”€â”€ storage/                # Vector store abstraction (Chroma)
â”‚   â””â”€â”€ chroma_store.py
â”œâ”€â”€ tools/                  # Search & filtering tools
â”‚   â”œâ”€â”€ text_search.py
â”‚   â”œâ”€â”€ image_search.py
â”‚   â”œâ”€â”€ metadata_filter.py
â”‚   â””â”€â”€ unified_search.py
â”œâ”€â”€ llm/                    # LLM client & system prompt
â”‚   â””â”€â”€ llm.py
â”œâ”€â”€ utilities/              # Helpers (S3 URLs, viewers)
â”‚   â””â”€â”€ url_generator.py
â”œâ”€â”€ inspectors/             # Debug & inspection utilities
â”‚   â””â”€â”€ chroma_inspector.py
â”œâ”€â”€ data/chroma/            # Persistent vector DB (EBS-backed)
â”œâ”€â”€ tmp/images/             # Temporary image storage
â”œâ”€â”€ entrypoint/             # CLI utilities
â”‚   â””â”€â”€ cli_agent.py
â”œâ”€â”€ frontend/               # Static frontend (served by FastAPI)
â””â”€â”€ requirements.txt
```

---

## Development Notes

* Docker is used for repeatable deployments
* EBS ensures embeddings persist across restarts
* The system currently supports **manual ingestion** only

---

## Roadmap

* ğŸ“± Automatic phone gallery sync
* ğŸ”„ Background re-embedding on metadata updates
* ğŸ§‘ Face clustering & people search
* ğŸ•°ï¸ Timeline-based photo exploration
* ğŸ“ Improved mobile-first UI

---

## Philosophy

This project prioritizes:

* **Privacy over exposure**
* **Reasoned AI over hallucinations**
* **Simple infrastructure over over-engineering**

It is intentionally built to scale **only when needed**.
